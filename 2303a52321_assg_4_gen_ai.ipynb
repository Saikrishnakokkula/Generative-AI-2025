{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN18QELAxlUYCPELRAXJrMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saikrishnakokkula/Generative-AI-2025/blob/main/2303a52321_assg_4_gen_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X_train = np.array([[0.1, 0.2, 0.3],\n",
        "                    [0.2, 0.3, 0.4],\n",
        "                    [0.3, 0.4, 0.5],\n",
        "                    [0.5, 0.6, 0.7],\n",
        "                    [0.1, 0.3, 0.5],\n",
        "                    [0.2, 0.4, 0.6],\n",
        "                    [0.3, 0.5, 0.7],\n",
        "                    [0.4, 0.6, 0.8],\n",
        "                    [0.5, 0.7, 0.1]])\n",
        "\n",
        "y_train = np.array([0.14, 0.20, 0.26, 0.38, 0.22, 0.28, 0.34, 0.40, 0.22])\n",
        "\n",
        "\n",
        "weights = np.random.randn(3)\n",
        "bias = np.random.randn(1)\n",
        "\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 1000\n",
        "\n",
        "# Define the Mean Squared Error (MSE) function\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Training the ANN using Gradient Descent and Backpropagation\n",
        "for epoch in range(epochs):\n",
        "    # Forward Pass: Linear Output (no activation)\n",
        "    y_pred = np.dot(X_train, weights) + bias\n",
        "\n",
        "    # Calculate the error (MSE)\n",
        "    error = y_pred - y_train\n",
        "\n",
        "    # Backpropagation: Compute Gradients\n",
        "    d_weights = (2/len(X_train)) * np.dot(X_train.T, error)  # Gradient w.r.t weights\n",
        "    d_bias = (2/len(X_train)) * np.sum(error)  # Gradient w.r.t bias\n",
        "\n",
        "    # Update weights and bias using gradient descent\n",
        "    weights -= learning_rate * d_weights\n",
        "    bias -= learning_rate * d_bias\n",
        "\n",
        "    # Calculate the MSE at every 100th epoch for monitoring\n",
        "    if epoch % 100 == 0:\n",
        "        mse = mean_squared_error(y_train, y_pred)\n",
        "        print(f'Epoch {epoch}: MSE = {mse:.4f}')\n",
        "\n",
        "# After training, print the final weights and bias\n",
        "print(\"\\nFinal Weights:\", weights)\n",
        "print(\"Final Bias:\", bias)\n",
        "\n",
        "# Step 3: Calculate the Mean Squared Error for the test data\n",
        "X_test = np.array([[0.6, 0.7, 0.8],\n",
        "                   [0.7, 0.8, 0.9]])\n",
        "\n",
        "y_test = np.array([0.44, 0.50])\n",
        "\n",
        "# Predict the output for test data\n",
        "y_test_pred = np.dot(X_test, weights) + bias\n",
        "\n",
        "# Calculate the MSE for the test data\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "print(f\"\\nTest MSE: {test_mse:.4f}\")\n",
        "\n",
        "# Step 4: Function to accept user input and predict the output\n",
        "def predict(x1, x2, x3):\n",
        "    input_data = np.array([x1, x2, x3])\n",
        "    prediction = np.dot(input_data, weights) + bias\n",
        "    return prediction\n",
        "\n",
        "# Step 5: Continuously accept input from the user\n",
        "print(\"\\nType 'exit' to quit the program.\")\n",
        "\n",
        "while True:\n",
        "    # Taking user input for x1, x2, and x3 dynamically\n",
        "    try:\n",
        "        x1 = input(\"\\nEnter value for x1: \")\n",
        "        if x1.lower() == 'exit':\n",
        "            break\n",
        "        x1 = float(x1)\n",
        "\n",
        "        x2 = input(\"Enter value for x2: \")\n",
        "        if x2.lower() == 'exit':\n",
        "            break\n",
        "        x2 = float(x2)\n",
        "\n",
        "        x3 = input(\"Enter value for x3: \")\n",
        "        if x3.lower() == 'exit':\n",
        "            break\n",
        "        x3 = float(x3)\n",
        "\n",
        "        # Predict the output using the trained model\n",
        "        predicted_output = predict(x1, x2, x3)\n",
        "        print(f\"\\nPredicted output: {predicted_output[0]:.4f}\")\n",
        "    except ValueError:\n",
        "        print(\"Invalid input! Please enter numeric values for x1, x2, and x3.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1jCC3LjJNKj",
        "outputId": "6d3788fb-6d59-446d-bbf8-b61bef8ba4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: MSE = 2.4856\n",
            "Epoch 100: MSE = 0.0039\n",
            "Epoch 200: MSE = 0.0010\n",
            "Epoch 300: MSE = 0.0003\n",
            "Epoch 400: MSE = 0.0002\n",
            "Epoch 500: MSE = 0.0001\n",
            "Epoch 600: MSE = 0.0001\n",
            "Epoch 700: MSE = 0.0001\n",
            "Epoch 800: MSE = 0.0001\n",
            "Epoch 900: MSE = 0.0001\n",
            "\n",
            "Final Weights: [-0.12894539  0.41201563  0.29332328]\n",
            "Final Bias: [-0.02470162]\n",
            "\n",
            "Test MSE: 0.0004\n",
            "\n",
            "Type 'exit' to quit the program.\n",
            "\n",
            "Enter value for x1: 0.5\n",
            "Enter value for x2: 0.4\n",
            "Enter value for x3: 0.7\n",
            "\n",
            "Predicted output: 0.2810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the dataset (Training Data from Table 3)\n",
        "X_train = np.array([[0.1, 0.2, 0.3],\n",
        "                    [0.2, 0.3, 0.4],\n",
        "                    [0.3, 0.4, 0.5],\n",
        "                    [0.5, 0.6, 0.7],\n",
        "                    [0.1, 0.3, 0.5],\n",
        "                    [0.2, 0.4, 0.6],\n",
        "                    [0.3, 0.5, 0.7],\n",
        "                    [0.4, 0.6, 0.8],\n",
        "                    [0.5, 0.7, 0.1]])\n",
        "\n",
        "y_train = np.array([0.5349, 0.5498, 0.5646, 0.5939, 0.5548, 0.5695, 0.5842, 0.5987, 0.5548])\n",
        "\n",
        "# Define the dataset (Test Data from Table 4)\n",
        "X_test = np.array([[0.6, 0.7, 0.8],\n",
        "                   [0.7, 0.8, 0.9]])\n",
        "\n",
        "y_test = np.array([0.6083, 0.6225])\n",
        "\n",
        "# Initialize weights and bias (3 input features, 1 output)\n",
        "weights = np.random.randn(3)  # 3 input features\n",
        "bias = np.random.randn(1)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of Sigmoid Function\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# Mean Squared Error (MSE) function\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Training the ANN using Gradient Descent and Backpropagation\n",
        "for epoch in range(epochs):\n",
        "    # Forward Pass: Linear Output\n",
        "    linear_output = np.dot(X_train, weights) + bias\n",
        "    y_pred = sigmoid(linear_output)\n",
        "\n",
        "    # Calculate the error (MSE)\n",
        "    error = y_pred - y_train\n",
        "\n",
        "    # Backpropagation: Compute Gradients\n",
        "    d_output = error * sigmoid_derivative(linear_output)  # Derivative of sigmoid\n",
        "    d_weights = (1 / len(X_train)) * np.dot(X_train.T, d_output)  # Gradient w.r.t weights\n",
        "    d_bias = (1 / len(X_train)) * np.sum(d_output)  # Gradient w.r.t bias\n",
        "\n",
        "    # Update weights and bias using gradient descent\n",
        "    weights -= learning_rate * d_weights\n",
        "    bias -= learning_rate * d_bias\n",
        "\n",
        "    # Calculate MSE at every 1000th epoch for monitoring\n",
        "    if epoch % 1000 == 0:\n",
        "        mse = mean_squared_error(y_train, y_pred)\n",
        "        print(f'Epoch {epoch}: MSE = {mse:.4f}')\n",
        "\n",
        "# After training, print the final weights and bias\n",
        "print(\"\\nFinal Weights:\", weights)\n",
        "print(\"Final Bias:\", bias)\n",
        "\n",
        "# Step 4: Calculate Mean Squared Error for the test data\n",
        "y_test_pred = sigmoid(np.dot(X_test, weights) + bias)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "print(f\"\\nTest MSE: {test_mse:.4f}\")\n",
        "\n",
        "# Step 5: Function to accept user input and predict the output\n",
        "def predict(x1, x2, x3):\n",
        "    input_data = np.array([x1, x2, x3])\n",
        "    prediction = sigmoid(np.dot(input_data, weights) + bias)\n",
        "    return prediction\n",
        "\n",
        "# Step 6: Dynamically accept input from the user\n",
        "print(\"\\nType 'exit' to quit the program.\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        x1 = input(\"\\nEnter value for x1: \")\n",
        "        if x1.lower() == 'exit':\n",
        "            break\n",
        "        x1 = float(x1)\n",
        "\n",
        "        x2 = input(\"Enter value for x2: \")\n",
        "        if x2.lower() == 'exit':\n",
        "            break\n",
        "        x2 = float(x2)\n",
        "\n",
        "        x3 = input(\"Enter value for x3: \")\n",
        "        if x3.lower() == 'exit':\n",
        "            break\n",
        "        x3 = float(x3)\n",
        "\n",
        "        # Predict the output using the trained model\n",
        "        predicted_output = predict(x1, x2, x3)\n",
        "        print(f\"\\nPredicted output: {predicted_output[0]:.4f}\")\n",
        "    except ValueError:\n",
        "        print(\"Invalid input! Please enter numeric values for x1, x2, and x3.\")\n"
      ],
      "metadata": {
        "id": "tG21QVqAJzLD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}